{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c14d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import yaml\n",
    "import math\n",
    "import re\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.stats import sem\n",
    "from os.path import join\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c35343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def atof(text):\n",
    "    try:\n",
    "        retval = float(text)\n",
    "    except ValueError:\n",
    "        retval = text\n",
    "    return retval\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    float regex comes from https://stackoverflow.com/a/12643073/190597\n",
    "    '''\n",
    "    return [ atof(c) for c in re.split(r'[+-]?([0-9]+(?:[.][0-9]*)?|[.][0-9]+)', text) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cbfe7",
   "metadata": {},
   "source": [
    "## Cumulative Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de121d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate NSIL table row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab369f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_acc(example_dir, num_epochs=20):\n",
    "    \n",
    "    nsil_repeats_dir = join(example_dir, 'saved_results', 'repeats')\n",
    "    for d_idx, dataset in enumerate(['meta_abd_data_sum', 'meta_abd_data_prod']):\n",
    "        nsil_accs = []\n",
    "        max_acc = 0\n",
    "        nsil_dir = nsil_repeats_dir + '/' + dataset\n",
    "        repeats = os.listdir(nsil_dir)\n",
    "        repeats = [r for r in repeats if r != '.DS_Store']\n",
    "        repeats.sort(key=natural_keys)\n",
    "\n",
    "        # X data is just epoch number\n",
    "        full_range = num_epochs + 1\n",
    "        X = list(range(full_range))\n",
    "\n",
    "        for idx, i in enumerate(repeats):\n",
    "            with open(join(nsil_dir, i, 'test_log.json'), 'r') as jf:\n",
    "                tl = json.loads(jf.read())\n",
    "            if str(num_epochs) not in tl:\n",
    "                print('Repeat not complete:')\n",
    "                print(join(nsil_dir, i, 'test_log.json'))\n",
    "                continue\n",
    "            acc = tl[str(num_epochs)]['network_accuracy']['digit']\n",
    "            if acc > max_acc:\n",
    "                max_acc = acc\n",
    "            nsil_accs.append(acc)\n",
    "        \n",
    "        net_acc = np.mean(np.array(nsil_accs))\n",
    "        net_err = sem(np.array(nsil_accs))\n",
    "        print(f'Dataset: {dataset}, Avg network accuracy: {net_acc} ({net_err})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d7ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: meta_abd_data_sum, Avg network accuracy: 0.9831800000000002 (0.0005978294071054137)\n",
      "Dataset: meta_abd_data_prod, Avg network accuracy: 0.9805400000000001 (0.0005173006862551082)\n"
     ]
    }
   ],
   "source": [
    "example = '../../../examples/recursive_arithmetic'\n",
    "get_network_acc(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842765f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "def conv_net(out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, 3, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, 3, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Dropout(0.25),\n",
    "        Flatten(),\n",
    "        nn.Linear(9216, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128, out_dim),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.enc = conv_net(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.enc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc439aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "MNIST_TEST = DataLoader(MNIST(root='../../../data', train=False, download=False, transform=MNIST_transform), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a64bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_preds(_net, _loader):\n",
    "    with torch.no_grad():\n",
    "        all_preds = torch.tensor([], device='cpu')\n",
    "        for data, targets in _loader:\n",
    "            outputs = _net(data)\n",
    "            confs, preds = torch.max(outputs, 1)\n",
    "            all_preds = torch.cat((all_preds, preds.to('cpu')), 0)\n",
    "        return all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b66502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each repeat, at epoch 10, load network, get test predictions, compute MAE\n",
    "def task_results(example, data_files):\n",
    "    \n",
    "    for dataset in data_files:        \n",
    "        nsil_dir = join(example, 'saved_results', 'repeats', dataset)\n",
    "        repeats = os.listdir(nsil_dir)\n",
    "        repeats = [r for r in repeats if r != '.DS_Store']\n",
    "        repeats.sort(key=natural_keys)\n",
    "        \n",
    "        for test_file in data_files[dataset]:\n",
    "            with open(join(example, 'data', test_file), 'r') as f:\n",
    "                TASK_DATA = yaml.load(f, Loader=yaml.Loader)\n",
    "        \n",
    "            results = []\n",
    "            for idx, i in enumerate(repeats):\n",
    "                try:\n",
    "                    net_weights_file = join(nsil_dir, i, 'networks', 'net_digit_iteration_20.pt')\n",
    "                    net = Net(10)\n",
    "                    net.load_state_dict(torch.load(net_weights_file, map_location=torch.device('cpu')))\n",
    "                    net.eval()\n",
    "                except:\n",
    "                    print(f\"Skipping repeat {i} as no iteration 10 network...\")\n",
    "                    continue\n",
    "\n",
    "                # Get network predictions on test images\n",
    "                nn_preds = get_nn_preds(net, MNIST_TEST)\n",
    "\n",
    "                # For each example in test set, compute metrics\n",
    "                task_preds = []\n",
    "                task_targets = []\n",
    "                for ex in TASK_DATA:\n",
    "                    ex_preds = [int(nn_preds[x].item()) for x in ex.x_idxs]\n",
    "                    if 'sum' in dataset:\n",
    "                        task_pred = sum(ex_preds)\n",
    "                    else:\n",
    "                        task_pred = np.prod(np.array(ex_preds))\n",
    "                    task_preds.append(task_pred)\n",
    "                    task_targets.append(ex.y)\n",
    "                \n",
    "                    \n",
    "                # Compute MAE or logMAE\n",
    "                if 'sum' in dataset:\n",
    "                    test_loss = torch.nn.L1Loss(reduction='sum')(\n",
    "                        torch.FloatTensor(task_preds), torch.FloatTensor(task_targets)).item()\n",
    "                else:\n",
    "                    test_loss = torch.nn.L1Loss(reduction='sum')(\n",
    "                        torch.log(torch.FloatTensor(task_preds)+1e-10),\n",
    "                        torch.log(torch.FloatTensor(task_targets)+1e-10)).item()\n",
    "                test_loss /= len(TASK_DATA)\n",
    "                results.append(test_loss)\n",
    "            \n",
    "            # Compute average over repeats\n",
    "            avg = np.mean(np.array(results))\n",
    "            std_err = sem(np.array(results))\n",
    "            if 'prod' in dataset:\n",
    "                mae_type = 'logMAE'\n",
    "            else:\n",
    "                mae_type = 'MAE'\n",
    "            print(f'File: {test_file}, {mae_type}: {avg:f} ({std_err:f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3857b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fs = {\n",
    "    'meta_abd_data_sum': ['mysum_full_test.yaml', 'mysum_full_test_10.yaml', 'mysum_full_test_100.yaml'],\n",
    "    'meta_abd_data_prod': ['myprod_full_test.yaml', 'myprod_full_test_10.yaml', 'myprod_full_test_15.yaml']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647e86e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: mysum_full_test.yaml, MAE: 0.238260 (0.010211)\n",
      "File: mysum_full_test_10.yaml, MAE: 0.625320 (0.026914)\n",
      "File: mysum_full_test_100.yaml, MAE: 4.449560 (0.177717)\n",
      "File: myprod_full_test.yaml, logMAE: 0.321787 (0.017189)\n",
      "File: myprod_full_test_10.yaml, logMAE: 0.528803 (0.030440)\n",
      "File: myprod_full_test_15.yaml, logMAE: 2.478133 (0.103972)\n"
     ]
    }
   ],
   "source": [
    "task_results(example, d_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55609254",
   "metadata": {},
   "source": [
    "## 2 Two-Digit Arithmetic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63d9220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = r'''\n",
    "\\begin{table*}[]\n",
    "\\centering\n",
    "\\resizebox{0.8\\linewidth}{!}{%\n",
    "\\begin{tabular}{@{}lllllll@{}}\n",
    "\\cmidrule(l){2-7}\n",
    "\\multicolumn{1}{c}{} & \\multicolumn{3}{c}{\\textbf{Addition}}                                             & \\multicolumn{3}{c}{\\textbf{E9P}}                                                  \\\\ \\cmidrule(l){2-7}\n",
    "Dataset \\% & \\multicolumn{1}{c}{\\textbf{100}} & \\multicolumn{1}{c}{\\textbf{10}} & \\multicolumn{1}{c}{\\textbf{5}} & \\multicolumn{1}{c}{\\textbf{100}} & \\multicolumn{1}{c}{\\textbf{10}} & \\multicolumn{1}{c}{\\textbf{5}} \\\\ \\midrule\n",
    "ff_nsl\n",
    "NeurASP\n",
    "nsil\n",
    "\\end{tabular}\n",
    "}\n",
    "\\caption{Non-Recursive Arithmetic naive baseline results. Standard error over 5 repeats is shown in parentheses.}\n",
    "\\label{tab:non_recursive_naive}\n",
    "\\end{table*}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0094e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FF-NSL/NeurASP\n",
    "def get_baseline_arithmetic(base):\n",
    "    baselines = ['ff_nsl', 'NeurASP']\n",
    "    tasks = ['sum', 'e9p']\n",
    "    pcts = [100,10,5]\n",
    "    for b in baselines:\n",
    "        b_row = ''\n",
    "        for t in tasks:\n",
    "            for p in pcts:\n",
    "                # Load results\n",
    "                with open(f'../../../examples/arithmetic/baselines/saved_results/{t}/{b}/{p}/results.json') as rf:\n",
    "                    rf = json.loads(rf.read())\n",
    "                    res = f\"{rf['task']['acc']:.{4}f} ({rf['task']['std_err']:.{4}f})\"\n",
    "                    b_row += f'{res} & '\n",
    "        if b == 'ff_nsl':\n",
    "            b_row = 'FF-NSL & ' + b_row[:-2] + r'\\\\'\n",
    "        else:\n",
    "            b_row = 'NeurASP & ' + b_row[:-2] + r'\\\\ \\midrule'\n",
    "        \n",
    "        base = base.replace(b, b_row)\n",
    "    return base\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc54f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nsil_arithmetic(nsil_dir, base):\n",
    "    nsil_row = ''\n",
    "    tasks = ['sum', 'e9p']\n",
    "    pcts = [100,10,5]\n",
    "    for t in tasks:\n",
    "        for p in pcts:\n",
    "            # Get 5 repeat average\n",
    "            nsl_dir = nsil_dir+'/'+str(t)+'/'+str(p)\n",
    "            repeats = os.listdir(nsl_dir)\n",
    "            repeats = [r for r in repeats if r != '.DS_Store']\n",
    "            repeats.sort(key=natural_keys)\n",
    "\n",
    "            all_results_epoch = []\n",
    "            for idx, i in enumerate(repeats):\n",
    "                if idx < 5:\n",
    "                    # Read in test_log and get end-to-end accuracy at this epoch\n",
    "                    with open(join(nsl_dir, i, 'test_log.json'), 'r') as jf:\n",
    "                        tl = json.loads(jf.read())\n",
    "                        acc = tl[str(20)]['end_to_end_acc']\n",
    "                        all_results_epoch.append(acc)\n",
    "\n",
    "            # Compute mean and std err across all repeats\n",
    "            nsl_mean = np.mean(all_results_epoch)\n",
    "            nsl_err = sem(all_results_epoch)\n",
    "            res = f\"{nsl_mean:.{4}f} ({nsl_err:.{4}f})\"\n",
    "            nsil_row += f'{res} & '\n",
    "            \n",
    "    nsil_row = 'NSIL & ' + nsil_row[:-2] + r'\\\\ \\bottomrule'\n",
    "    base = base.replace('nsil', nsil_row)\n",
    "    return base\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0102ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[]\n",
      "\\centering\n",
      "\\resizebox{0.8\\linewidth}{!}{%\n",
      "\\begin{tabular}{@{}lllllll@{}}\n",
      "\\cmidrule(l){2-7}\n",
      "\\multicolumn{1}{c}{} & \\multicolumn{3}{c}{\\textbf{Addition}}                                             & \\multicolumn{3}{c}{\\textbf{E9P}}                                                  \\\\ \\cmidrule(l){2-7}\n",
      "Dataset \\% & \\multicolumn{1}{c}{\\textbf{100}} & \\multicolumn{1}{c}{\\textbf{10}} & \\multicolumn{1}{c}{\\textbf{5}} & \\multicolumn{1}{c}{\\textbf{100}} & \\multicolumn{1}{c}{\\textbf{10}} & \\multicolumn{1}{c}{\\textbf{5}} \\\\ \\midrule\n",
      "FF-NSL & 0.9753 (0.0021) & 0.9362 (0.0029) & 0.9151 (0.0058) & 0.9809 (0.0016) & 0.9513 (0.0030) & 0.9346 (0.0051) \\\\\n",
      "NeurASP & 0.9762 (0.0013) & 0.9492 (0.0016) & 0.9149 (0.0051) & 0.9797 (0.0015) & 0.9642 (0.0009) & 0.9500 (0.0014) \\\\ \\midrule\n",
      "NSIL & 0.9762 (0.0013) & 0.9449 (0.0025) & 0.8782 (0.0134) & 0.9816 (0.0009) & 0.9634 (0.0007) & 0.9510 (0.0016) \\\\ \\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Non-Recursive Arithmetic naive baseline results. Standard error over 5 repeats is shown in parentheses.}\n",
      "\\label{tab:non_recursive_naive}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with_baselines = get_baseline_arithmetic(base)\n",
    "print(get_nsil_arithmetic('../../../examples/arithmetic/saved_results/repeats', with_baselines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa5982",
   "metadata": {},
   "source": [
    "## 3) Hitting Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d798c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = r'''\n",
    "\\begin{table*}[]\n",
    "\\centering\n",
    "\\resizebox{0.6\\linewidth}{!}{%\n",
    "\\begin{tabular}{@{}lllll@{}}\n",
    "\\cmidrule(l){2-5}\n",
    "\\multicolumn{1}{c}{}        & \\multicolumn{2}{c}{\\textbf{HS}}                                       & \\multicolumn{2}{c}{\\textbf{CHS}}                                      \\\\ \\cmidrule(l){2-5} \n",
    "Dataset & \\multicolumn{1}{c}{\\textbf{MNIST}} & \\multicolumn{1}{c}{\\textbf{FashionMNIST}} & \\multicolumn{1}{c}{\\textbf{MNIST}} & \\multicolumn{1}{c}{\\textbf{FashionMNIST}} \\\\ \\midrule\n",
    "ff_nsl\n",
    "NeurASP\n",
    "nsil\n",
    "\\end{tabular}\n",
    "}\n",
    "\\caption{Hitting Sets naive baseline results. Standard error over 5 repeats is shown in parentheses.}\n",
    "\\label{tab:hitting_sets_naive}\n",
    "\\end{table*}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7be5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FF-NSL/NeurASP\n",
    "def get_baseline_hitting_sets(base):\n",
    "    baselines = ['ff_nsl', 'NeurASP']\n",
    "    tasks = ['HS_mnist', 'HS_fashion_mnist', 'CHS_mnist', 'CHS_fashion_mnist']\n",
    "    for b in baselines:\n",
    "        b_row = ''\n",
    "        for t in tasks:\n",
    "            # Load results\n",
    "            with open(f'../../../examples/hitting_sets/baselines/saved_results/{t}/{b}/results.json') as rf:\n",
    "                rf = json.loads(rf.read())\n",
    "                res = f\"{rf['task']['acc']:.{4}f} ({rf['task']['std_err']:.{4}f})\"\n",
    "                b_row += f'{res} & '\n",
    "        if b == 'ff_nsl':\n",
    "            b_row = 'FF-NSL & ' + b_row[:-2] + r'\\\\'\n",
    "        else:\n",
    "            b_row = 'NeurASP & ' + b_row[:-2] + r'\\\\ \\midrule'\n",
    "        \n",
    "        base = base.replace(b, b_row)\n",
    "    return base\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd5cc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nsil_hitting_sets(nsil_dir, base):\n",
    "    nsil_row = ''\n",
    "    tasks = ['HS_mnist', 'HS_fashion_mnist', 'CHS_mnist', 'CHS_fashion_mnist']\n",
    "    for t in tasks:\n",
    "        # Get 5 repeat average\n",
    "        nsl_dir = nsil_dir+'/'+str(t)+'/100'\n",
    "        repeats = os.listdir(nsl_dir)\n",
    "        repeats = [r for r in repeats if r != '.DS_Store']\n",
    "        repeats.sort(key=natural_keys)\n",
    "\n",
    "        all_results_epoch = []\n",
    "        for idx, i in enumerate(repeats):\n",
    "            if idx < 5:\n",
    "                # Read in test_log and get end-to-end accuracy at this epoch\n",
    "                with open(join(nsl_dir, i, 'test_log.json'), 'r') as jf:\n",
    "                    tl = json.loads(jf.read())\n",
    "                    acc = tl[str(20)]['end_to_end_acc']\n",
    "                    all_results_epoch.append(acc)\n",
    "\n",
    "        # Compute mean and std err across all repeats\n",
    "        nsl_mean = np.mean(all_results_epoch)\n",
    "        nsl_err = sem(all_results_epoch)\n",
    "        res = f\"{nsl_mean:.{4}f} ({nsl_err:.{4}f})\"\n",
    "        nsil_row += f'{res} & '\n",
    "            \n",
    "    nsil_row = 'NSIL & ' + nsil_row[:-2] + r'\\\\ \\bottomrule'\n",
    "    base = base.replace('nsil', nsil_row)\n",
    "    return base\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0676b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[]\n",
      "\\centering\n",
      "\\resizebox{0.6\\linewidth}{!}{%\n",
      "\\begin{tabular}{@{}lllll@{}}\n",
      "\\cmidrule(l){2-5}\n",
      "\\multicolumn{1}{c}{}        & \\multicolumn{2}{c}{\\textbf{HS}}                                       & \\multicolumn{2}{c}{\\textbf{CHS}}                                      \\\\ \\cmidrule(l){2-5} \n",
      "\\multicolumn{1}{c}{Dataset} & \\multicolumn{1}{c}{\\textbf{MNIST}} & \\multicolumn{1}{c}{\\textbf{FashionMNIST}} & \\multicolumn{1}{c}{\\textbf{MNIST}} & \\multicolumn{1}{c}{\\textbf{FashionMNIST}} \\\\ \\midrule\n",
      "FF-NSL & 0.9937 (0.0017) & 0.8816 (0.0110) & 0.9962 (0.0012) & 0.9563 (0.0034) \\\\\n",
      "NeurASP & 0.9981 (0.0013) & 0.8975 (0.0041) & 0.9994 (0.0006) & 0.9538 (0.0070) \\\\ \\midrule\n",
      "NSIL & 0.9962 (0.0012) & 0.8747 (0.0053) & 0.9981 (0.0013) & 0.9544 (0.0021) \\\\ \\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Hitting Sets naive baseline results. Standard error over 5 repeats is shown in parentheses.}\n",
      "\\label{tab:hitting_sets_naive}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with_baselines = get_baseline_hitting_sets(base)\n",
    "print(get_nsil_hitting_sets('../../../examples/hitting_sets/saved_results/repeats', with_baselines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd3536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
